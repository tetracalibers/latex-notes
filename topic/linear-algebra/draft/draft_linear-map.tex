\documentclass[../../../topic_linear-algebra]{subfiles}

\usepackage{xr-hyper}
\externaldocument{../../../.tex_intermediates/topic_linear-algebra}

\begin{document}

\sectionline
\section{線形写像}
\marginnote{
  \refweb{線形代数の基礎のキソ}{https://www1.econ.hit-u.ac.jp/kawahira/courses/kiso/01-senkei.pdf}
}

$U$と$V$をベクトル空間とする。

写像$f \colon U \to V$が与えられたとき、これは$U$の出来事、構造、その他もろもろの情報を$V$に投影していると考えられる。

\br

このとき、その「写り方」にはどのような性質を期待するべきであろうか？

もっとも素朴な期待は、$U$はベクトル空間なのだから、写った先$f(U)$でもベクトル空間としての代数的構造（ベクトルどうしの和・定数倍に関する関係式）が保存されるという状況である。

\begin{mindflow}
  \placeholder{線形写像の定義}
\end{mindflow}

たとえば、和の保存
\begin{equation*}
  f(\vb*{u}_1 + \vb*{u}_2) = f(\vb*{u}_1) + f(\vb*{u}_2)
\end{equation*}
は、次のように解釈できる。

\begin{enumerate}
  \item $U$の側で、$\vb*{u}_1$と$\vb*{u}_2$が足され、$\vb*{u}_1 + \vb*{u}_2$が得られた。
  \item この現象を$f$というレンズを通して$V$に写すと、$f(\vb*{u}_1)$と$f(\vb*{u}_2)$が足され、$f(\vb*{u}_1) + f(\vb*{u}_2)$が得られたように見える。
\end{enumerate}

\subsection{比例関数の一般化}

線形写像の特徴づけとして、「比例関数の一般化」という考え方もできる。

もっとも簡単な関数である比例関数が満たすべき性質を、高次元なりに抽象化し、実現しているのが線形写像だとも考えられる。

\subsection{線形写像と微分}

線形写像は「局所的には」ありふれている。

あらゆる微分可能な関数は、あらゆる場所で「線形写像＋誤差」と局所的に表現される。

局所的に線形写像として近似するのが微分ともいえる。

\sectionline
\section{$A$倍写像}
\marginnote{\refbookS p47}

縦ベクトルに左から行列をかけたものは、縦ベクトルとなる。

より具体的には、$n$次元縦ベクトル$\vb*{v}$に対して、$m \times n$型行列$A$を左からかけたものは、$m$次元縦ベクトルとなる。
\begin{equation*}
  \underset{\eqnmarkbox[cyan]{_dim_m}{m} \times \eqnmarkbox[magenta]{dim_n1}{n}}{A} \cdot \underset{\eqnmarkbox[magenta]{dim_n2}{n} \times \eqnmarkbox[cyan]{_dim_1}{1}}{\vb*{v}} = \underset{\eqnmarkbox[cyan]{_dim_m}{m} \times \eqnmarkbox[cyan]{_dim_1}{1}}{A \vb*{v}}
\end{equation*}
\annotatetwo{below}{dim_n1}{dim_n2}{\bfseries\scriptsize 同じ}

このとき、行列は、あるベクトルを別なベクトルに対応させる役割を果たしている。

そこで、「左から行列をかける」という操作を、一種の\defref*{def:map}と考えることができる。

\begin{definition*}{$A$倍写像}
  $m \times n$型行列$A$に対し、次のようにおくことで定まる写像$f_A \colon K^n \to K^m$を、\keywordJE{$A$倍写像}{multiplication by A}という。
  \begin{equation*}
    f_A (\vb*{v}) = A \vb*{v}
  \end{equation*}
\end{definition*}

% \refbookS 命題2.2.1.1
\begin{theorem*}{$A$倍写像の線形性}
  $A$を$m \times n$型行列とすると、$A$倍写像$f_A\colon K^n \to K^m$は線形写像である。
\end{theorem*}

\begin{proof}
  \thmref{thm:matrix-vector-product-linear}より、
  \begin{gather*}
    f_A(\vb*{u} + \vb*{v}) = A(\vb*{u} + \vb*{v}) = A\vb*{u} + A\vb*{v} = f_A(\vb*{u}) + f_A(\vb*{v}) \\
    f_A(c\vb*{v}) = A(c\vb*{v}) = cA\vb*{v} = cf_A(\vb*{v})
  \end{gather*}
  が成り立つので、$f_A$は線形写像である。$\qed$
\end{proof}

\sectionline
\section{行列と線形写像の同一視}
\marginnote{\refbookS p48}

行列$A$を、$n$個の$m$次元ベクトル$\vb*{a}_1, \ldots, \vb*{a}_n \in K^m$を並べたものとみなす。
\begin{equation*}
  A = \begin{pmatrix}
    \vb*{a}_1 & \vb*{a}_2 & \cdots & \vb*{a}_n
  \end{pmatrix}
\end{equation*}

このとき、$A$倍写像$f_A\colon K^n \to K^m$は、次のように定義される。
\begin{equation*}
  f_A(\vb*{v}) = A \vb*{v} \quad (\vb*{v} \in K^n)
\end{equation*}
  
標準基底$\vb*{e}_1, \ldots, \vb*{e}_n \in K^n$に作用させると、
\begin{equation*}
  f_A(\vb*{e}_i) = A \vb*{e}_i = \vb*{a}_i \quad (i = 1, \ldots, n)
\end{equation*}

よって、$A$倍写像$f_A$は、標準基底$\vb*{e}_1, \ldots, \vb*{e}_n \in K^n$を$\vb*{a}_1, \ldots, \vb*{a}_n \in K^m$に写す線形写像にほかならない。

\begin{mindflow}
  これより前のどこかで、行列の集合の記号$M_{mn}(K)$を導入する
\end{mindflow}

% \refbookS 命題2.2.1.2
\begin{theorem*}{行列と線形写像の同型対応}
  $m \times n$型行列$A$に対して、$A$倍写像$f_A\colon K^n \to K^m$を対応させる写像は同型である。
  \begin{equation*}
  \begin{array}{lclc}
    \Psi \colon & M_{mn}(K)         & \longrightarrow & \{ \text{線形写像} K^n \to K^m \}          \\
            & \rotatebox{90}{$\in$} &                 & \rotatebox{90}{$\in$} \\
            & A             & \longmapsto     & f_A
  \end{array}
\end{equation*}
\end{theorem*}

\begin{proof}
  $K^n$の標準基底を$\vb*{e}_1,\dots,\vb*{e}_n$、$K^m$の標準基底を$\vb*{\epsilon}_1,\dots,\vb*{\epsilon}_m$とする。

  また、$A\in M_{mn}(K)$の第$j$列を$\vb*{a}_j\in K^m$と書くことにする。
  
  \begin{subpattern}{\bfseries $\Psi$の定義と存在}
    \thmref{thm:linear-map-determined-by-basis}より、
    \begin{equation*}
      f_A(\vb*{e}_j) = \vb*{a}_j \quad (j=1,\dots,n)
    \end{equation*}
    を満たす線形写像$f_A\colon K^n\to K^m$が一意に存在する。
    
    よって、$A$を与えたときに$f_A$は一意に定まるため、写像$\Psi$が定義できる。
  \end{subpattern}
  
  \begin{subpattern}{\bfseries $\Psi$の単射性}
    $f_A=f_B$ならば、すべての$j$について次が成り立つ。
    \begin{equation*}
      \vb*{a}_j = A\vb*{e}_j =f_A(\vb*{e}_j)=f_B(\vb*{e}_j)=B\vb*{e}_j = \vb*{b}_j
    \end{equation*}
    したがって、$A,B$の列ベクトルは一致するため、$A=B$がいえる。
    
    よって、
    \begin{equation*}
      f_A = f_B \implies A = B
    \end{equation*}
    より、$\Psi$は\defref*{def:injective-map}である。 $\qed$
  \end{subpattern}
  
  \begin{subpattern}{\bfseries $\Psi$の全射性}
    任意の線形写像$g\colon K^n \to K^m$をとる。
    
    各$j$について$\vb*{w}_j=g(\vb*{e}_j)$とおき、行列$A$を次のように定める。
    \begin{equation*}
      A= \begin{pmatrix}
        \vb*{w}_1 & \cdots & \vb*{w}_n
      \end{pmatrix} \in M_{mn}(K)
    \end{equation*}
    すると、$f_A(\vb*{e}_j)=\vb*{w}_j=g(\vb*{e}_j)$ であるから、\thmref{thm:linear-map-equality-on-basis}より、$f_A=g$がしたがう。
    
    \br
    
    ゆえに、$\Psi$の像は任意の線形写像となるため、$\Psi$の像空間と線形写像全体の集合は一致する。
    よって、$\Psi$は\defref*{def:surjective-map}である。 $\qed$
  \end{subpattern}
  
  \begin{subpattern}{\bfseries $\Psi$の線形性}
    $A,B\in M_{mn}(K)$、$c_1,c_2\in K$とすると、
  \begin{equation*}
    (c_1 A+c_2 B)\vb*{e}_j = c_1 A\vb*{e}_j + c_2 B\vb*{e}_j
  \end{equation*}
  なので、基底$\{\vb*{e}_j\}$上で次が成り立つ。
  \begin{equation*}
    f_{c_1 A+c_2 B}(\vb*{e}_j) = c_1 f_A(\vb*{e}_j) + c_2 f_B(\vb*{e}_j)
  \end{equation*}
  
  \thmref{thm:linear-map-equality-on-basis}より、基底上で値が一致する線形写像は一意であるから、
  \begin{equation*}
    \Psi(c_1 A+c_2 B)=c_1 \Psi(A)+c_2 \Psi(B)
  \end{equation*}
  よって、$\Psi$は線形写像である。$\qed$
  \end{subpattern}  
\end{proof}

\br

行列$A$と線形写像$f_A$の間には一対一対応がある。

この同型が、行列$A$と線形写像$f_A$を同じものと考えることの根拠となっている。

\end{document}
