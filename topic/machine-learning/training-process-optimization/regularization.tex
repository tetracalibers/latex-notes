\documentclass[../../../topic_machine-learning]{subfiles}

\begin{document}

\sectionline
\section{正則化}
\marginnote{\refbookMA p93〜97、p99}

複雑なモデルは多くのパラメータを持ち、柔軟に調整することができる

しかし、モデルを柔軟にしすぎると過学習を起こす可能性がある

そこで、パラメータに制限（条件）をつけることで過学習を防ぐ手法として、\keywordJE{正則化}{regularization}がある

\begin{definition}{正則化}
  モデルの複雑さにペナルティを科す（モデルに格納できる情報の量を調整するか、モデルに格納できる情報の種類を制限する）ことで、最終的に過学習を防ぐ手法
\end{definition}

複数のモデルをテストし、性能と複雑さのバランスが最もよいものを選ぶことでモデルの最適化を図る方法もあるが、正則化を用いる場合は、モデルを何種類も訓練する必要はない

\br

正則化では、モデルを訓練するのは1回だけだが、モデルを訓練しながら次の2つの最適化も試みる

\begin{itemize}
  \item 性能を向上させる
  \item 複雑さを減らす
\end{itemize}

そのために、性能の指標と複雑度の指標を数値化し、それらを組み合わせた上で最適化問題を解くという方法をとる

\begin{itemize}
  \item \keywordJE{回帰誤差}{regression error}：モデルの性能（品質）の指標
  \item \keywordJE{正規化項}{regularization term}：モデルの複雑度の指標
\end{itemize}

\keyword{回帰誤差}として使われるのは、絶対誤差や二乗誤差などである

\keyword{正規化項}として使われるのは、モデルの\keyword{\en{L1}ノルム}や\keyword{\en{L2}ノルム}である

\br

これらを用いて、性能がよくあまり複雑ではないモデルを見つけ出すために、次のように変更された誤差関数を最小化する

\begin{equation*}
  \text{\bfseries 誤差} = \text{\bfseries 回帰誤差} + \text{\bfseries 正則化項}
\end{equation*}

\sectionline
\section{正則化パラメータ}
\marginnote{\refbookMA p100}

正則化を用いても、モデルの性能を向上させようとすると複雑さが増し、モデルを単純化しようとすると性能が低下するという網引き状態になることがある

その場合は、ハイパーパラメータを使って、性能と複雑度の間で調整を行う

\br

ここで使われるハイパーパラメータは、\keyword{正則化パラメータ}と呼ばれるもので、その目的はモデルの訓練プロセスにおいて、性能と単純さのどちらを重視すべきかを決めることにある

\br

正則化項に正則化パラメータ$\lambda$をかけたものに、回帰誤差を足し、その結果を使ってモデルを訓練する

\begin{equation*}
  \text{\bfseries 誤差} = \text{\bfseries 回帰誤差} + \lambda\cdot\text{\bfseries 正則化項}
\end{equation*}

\br

$\lambda$の値を大きくすると（おそらく次数の小さい）単純なモデルになり、データセットにあまりうまく適合しないことがある

そのため、\keyword{検証データセット}を使って、モデルの性能が最も良くなる$\lambda$の値を選択することが重要となる

\end{document}
